import os
import json
import time
import atexit
import queue
import argparse
import asyncio

from typing import Optional, Union, Any, List, Tuple, Literal, Dict, Set

import cv2 as cv
import numpy as np

import enums
import schemas
from core import BaseService
from db import RedisClient
from logger import CustomLogger
from settings import Settings, settings

from utils import validate_request
from utils import (
    hex_to_rgb,
    image_to_base64,
    draw_masks_on_image,
    mask_to_xyxy,
    mask_to_polygons,
)
from ai_module import SegmentAnything2


class Annotator:
    def __init__(
        self,
        task_uuid: str,
        config: schemas.InitModelIntercom,
        redis_client: RedisClient,
        logger: CustomLogger,
    ) -> None:
        self.uuid = task_uuid
        self.config = config
        self.redis = redis_client
        self.log = logger

    @property
    def status(self) -> enums.AnnotationStatusEnum:
        status = self.redis.get(self.status_key)
        if status is None:
            return enums.AnnotationStatusEnum.UNKNOWN
        return enums.AnnotationStatusEnum(status)

    @status.setter
    def status(self, value: enums.AnnotationStatusEnum):
        self.redis.set(self.status_key, value.value)

    @property
    def status_key(self) -> str:
        return f"task:{self.uuid}:annotation:status"

    @property
    def annotation_model(self) -> str:
        return self.config.ai_model.ai_model_name

    @property
    def video_source(self) -> str:
        return self.config.video.video_name

    def get_frame_idx_padding(self, frame_idx: int) -> str:
        return str(frame_idx + 1).zfill(8)

    def get_image_path(self, frame_idx: int) -> str:
        return os.path.join(
            self.config.video.frames_path,
            self.get_frame_idx_padding(frame_idx=frame_idx) + ".jpg",
        )

    def __call__(
        self,
        segmentation_masks: np.ndarray,
        object_ids: List[Union[int, str]],
        frame_idx: int,
        color_mapping: Optional[Dict[str, str]] = None,
        label_mapping: Optional[Dict[str, str]] = None,
        export_type: Literal["bbox", "poylgon", "all"] = "all",
        *args,
        **kwargs,
    ) -> bool:
        """Exports single frame segmentation masks as bboxes and polygons to store in the redis
        to be ready when user want to export annotations

        Args:
            segmentation_masks (np.ndarray): segmentation masks generated by SAM2
            object_ids (List[str]): object ids in that frame
            frame_idx (int): current frame index to track which frame is anotated
            export_type (Literal["bbox", "poylgon","all"], optional): type of export. Defaults to "all".

        Raises:
            Exception: _description_
            Exception: _description_
            RuntimeError: _description_
            ValueError: _description_
            ValueError: _description_
            ValueError: _description_
            ValueError: _description_

        Returns:
            bool: true if storing is successful, false otherwise
        """
        annotation_meta = schemas.AnnotationMeta(
            annotation_model=self.annotation_model,
            video_source=self.video_source,
            frame_idx=frame_idx,
        )
        if export_type == "bbox" or export_type == "all":
            bbox_cover = self.export_bbox(
                frame_idx=frame_idx,
                out_object_ids=object_ids,
                masks=segmentation_masks,
                color_mapping=color_mapping if color_mapping else dict(),
                label_mapping=label_mapping if label_mapping else dict(),
            )
            bbox_annotations = self.get_annotation_object_from_bbox_cover(bbox_cover)
        else:
            bbox_annotations = list()

        if export_type == "polygon" or export_type == "all":
            polygon_cover = self.export_polygon(
                frame_idx=frame_idx,
                out_object_ids=object_ids,
                masks=segmentation_masks,
                color_mapping=color_mapping if color_mapping else dict(),
                label_mapping=label_mapping if label_mapping else dict(),
            )
            polygon_annotations = self.get_annotation_object_from_polygon_cover(
                polygon_cover
            )
        else:
            polygon_annotations = list()

        image_annotation = schemas.ImageAnnotation(
            image_id=f"{self.uuid}:{frame_idx}",
            image_path=self.get_image_path(frame_idx),
            meta=annotation_meta,
            bbox_annotations=bbox_annotations,
            polygon_annotations=polygon_annotations,
        )

        is_published = self.redis.set(
            f"task:{self.uuid}:annotation:{self.get_frame_idx_padding(frame_idx)}",
            image_annotation.model_dump_json(),
        )
        return is_published

    @staticmethod
    def get_annotation_object_from_bbox_cover(
        bbox_cover: schemas.BboxCover,
    ) -> List[schemas.BboxAnnotation]:
        """_summary_

        Args:
            bbox_cover (schemas.BboxCover): _description_

        Returns:
            List[schemas.Annotation]: _description_
        """
        annotation_list = list()
        for bbox in bbox_cover.bboxes:
            annotation = schemas.BboxAnnotation(
                id=str(bbox.id),
                xmin=bbox.xmin,
                ymin=bbox.ymin,
                xmax=bbox.xmax,
                ymax=bbox.ymax,
                label=bbox.label,
            )
            annotation_list.append(annotation)
        return annotation_list

    @staticmethod
    def get_annotation_object_from_polygon_cover(
        polygon_cover: schemas.PolygonCover,
    ) -> List[schemas.PolygonAnnotation]:
        """_summary_

        Args:
            polygon_cover (schemas.PolygonCover): _description_

        Returns:
            List[schemas.Annotation]: _description_
        """
        annotation_list = list()
        for polygon in polygon_cover.polygons:
            annotation = schemas.PolygonAnnotation(
                id=str(polygon.id),
                label=polygon.label,
                coordinates=polygon.coordinates,
            )
            annotation_list.append(annotation)
        return annotation_list

    def export_bbox(
        self,
        frame_idx: int,
        out_object_ids: List[Union[int, str]],
        masks: np.ndarray,
        color_mapping: Dict[str, str],
        label_mapping: Dict[str, str],
    ) -> schemas.BboxCover:
        """Returns BboxCover object via extracting bbox information from segmentation masks

        Args:
            frame_idx (int): corresponding frame index
            out_object_ids (List[Union[str, int]]): unique object ids
            masks (np.ndarray): segmentation masks
            color_mapping (Dict[str, str]): hex color mapping of object ids
            label_mapping (Dict[str, str]): object_id -> label


        Returns:
            schemas.BboxCover: BboxCover computed from masks
        """
        bboxes = mask_to_xyxy(masks, normlized=True)
        bbox_objects: List[schemas.BboxObject] = list()
        for obj_ids, bbox in zip(out_object_ids, bboxes):
            # print(f"{obj_ids=}, {bbox=}")
            bbox_objects.append(
                schemas.BboxObject(
                    id=obj_ids,
                    objecColor=color_mapping.get(str(obj_ids), "#FFFFFF"),
                    xmin=bbox[0],
                    ymin=bbox[1],
                    xmax=bbox[2],
                    ymax=bbox[3],
                    normalized=True,
                    label=label_mapping.get(str(obj_ids), None),
                )
            )
        return schemas.BboxCover(frame_number=frame_idx, bboxes=bbox_objects)

    def export_polygon(
        self,
        frame_idx: int,
        out_object_ids: List[Union[int, str]],
        masks: np.ndarray,
        color_mapping: Dict[str, str],
        label_mapping: Dict[str, str],
    ) -> schemas.PolygonCover:
        polygon_objects: List[schemas.PolygonObject] = list()
        for obj_id, mask in zip(out_object_ids, masks):
            polygon = mask_to_polygons(mask, normalized=True)
            for poly in polygon:
                polygon_object = schemas.PolygonObject(
                    id=obj_id,
                    objectColor=color_mapping.get(str(obj_id), "#FFFFFF"),
                    coordinates=poly.tolist(),
                    normalized=True,
                    label=label_mapping.get(str(obj_id), None),
                )
                polygon_objects.append(polygon_object)
        return schemas.PolygonCover(frame_number=frame_idx, polygons=polygon_objects)


class Worker(BaseService):
    def __init__(
        self, logger, worker_uuid: str, src_settings: Settings = settings
    ) -> None:
        logger.success(f"Worker {worker_uuid} started!")
        super().__init__(src_settings, logger)

        self.uuid = worker_uuid
        self.settings = src_settings

        self.redis = RedisClient(config=self.settings)

        self.task_queue: queue.Queue[schemas.ResponseCover] = queue.Queue()

        self.config: Optional[schemas.Intercom] = self.get_worker_config()
        if self.config is None:
            raise Exception("Could not get worker configuration")

        self.annotator = Annotator(
            task_uuid=self.uuid,
            config=self.config.task,
            redis_client=RedisClient(
                config=self.settings
            ),  # create new redis connection
            logger=logger,
        )

        self.model: SegmentAnything2 = SegmentAnything2(
            model_path=self.config.task.ai_model.checkpoint_path,  # type: ignore
            model_config=self.config.task.ai_model.config_path,  # type: ignore
        )

        # update status while loading the video
        self.redis.set(self.status_key, enums.TaskStatus.LOADING_VIDEO.value)
        try:
            self.model.init_state(video_dir=self.config.task.video.frames_path)  # type: ignore
            self.redis.set(self.status_key, enums.TaskStatus.READY.value)
        except Exception as err:
            self.redis.set(self.status_key, enums.TaskStatus.FAILED.value)
            raise Exception(f"Error initializing model: {err}")

        self.request_queue = queue.Queue()
        self.response_queue: queue.Queue[
            Union[schemas.SingleFrameResponseCover, schemas.ErrorResponseCover]
        ] = queue.Queue()
        self.__init_additional_threads()

        # to store object ids and the frame numbers they in it
        self.objects: Dict[str, Set[int]] = dict()
        # frame - point prompt mapping
        self.annotated_frames: Dict[int, List[schemas.SingleFrameAnnotationObject]] = (
            dict()
        )
        self._inference_run: bool = False

    @property
    def inference_run(self) -> bool:
        return self._inference_run

    @inference_run.setter
    def inference_run(self, value: bool):
        if not isinstance(value, bool):
            raise ValueError("Invalid value for inference_run")
        self._inference_run = value

    @property
    def video_w(self) -> int:
        return self.config.task.video.video_width

    @property
    def video_h(self) -> int:
        return self.config.task.video.video_height

    @property
    def status_key(self) -> str:
        return f"task:{self.uuid}:status"

    @property
    def config_key(self) -> str:
        return f"task:{self.uuid}:config"

    @property
    def request_key(self) -> str:
        return f"task:{self.uuid}:request"

    @property
    def response_key(self) -> str:
        return f"task:{self.uuid}:response"

    @property
    def annotation_status_key(self) -> str:
        return f"task:{self.uuid}:annotation:status"

    @property
    def status(self) -> enums.TaskStatus:
        status = self.redis.get(self.status_key)
        if status is None:
            return enums.TaskStatus.UNKNOWN
        return enums.TaskStatus(status)

    @status.setter
    def status(self, value: enums.TaskStatus):
        self.redis.set(self.status_key, value.value)

    def __init_additional_threads(self) -> None:
        self.add_thread(target=self.task_consumer, name="TaskConsumer Thread")
        self.add_thread(target=self.response_publisher, name="ResponsePublisher Thread")

    def stop(self):
        # self.redis.set(self.status_key, enums.TaskStatus.STOPPED.value)
        ## TODO: Set all keys a TTL to autoremove
        # task_keys = self.redis.get_keys_with_pattern(f"task:{self.uuid}:*")
        # for key in task_keys:
        #    self.redis.set_expiration(key=key, ttl=60 * 5)
        return super().stop()

    def get_worker_config(self) -> Optional[schemas.Intercom]:
        trial_count = 0
        while (not self.stop_event) or (trial_count < 5):
            msg = self.redis.get(self.config_key)
            if msg is None:
                trial_count += 1
                time.sleep(0.5)
                continue
            try:
                payload: schemas.Intercom = schemas.Intercom.model_validate_json(msg)
                return payload
            except Exception as e:
                self.log.error(f"Error parsing message: {e}")
                return None

    def response_publisher(self) -> None:
        while not self.stop_event.is_set():
            try:
                response = self.response_queue.get(block=False)
            except queue.Empty:
                time.sleep(0.5)
                continue
            if response is None:
                time.sleep(0.5)
                continue
            is_published = self.publish_response(response)
            if not is_published:
                self.log.error(f"Error publishing response: {response}")
                continue
            self.log.success(f"Published response: {response.msg_type}")

    def publish_response(self, response: schemas.ResponseCover) -> bool:
        """Publish single processed response to the response queue

        Args:
            response (schemas.ResponseCover): Created response object to be delivered

        Returns:
            bool: True if published successfully, False otherwise
        """
        try:
            is_publihsed = self.redis.queue(
                self.response_key, response.model_dump_json()
            )
            if not is_publihsed:
                self.log.error("Error publishing response")
                return False
            return True
        except Exception as e:
            self.log.critical(f"Error publishing response: {e}")
            return False

    def consume_requests(self) -> Optional[schemas.ResponseCover]:
        try:
            msg = self.redis.dequeue(self.request_key, count=1)
        except Exception as e:
            self.log.critical(f"Error consuming request: {e}")
            return None
        if not msg:
            return None
        try:
            # validate message
            task, is_valid = validate_request(json.loads(msg[0].decode("utf-8")))
            if not is_valid:
                self.log.error(f"Invalid message: {task}")
                return None
            return task
        except Exception as e:
            self.log.error(f"Error parsing message: {e}")
            return None

    def update_storage(
        self,
        frame_idx: int,
        object_ids: List[Union[int, str]],
        point_prompts: List[schemas.SingleFrameAnnotationObject],
    ) -> None:
        if not object_ids:
            return
        for obj_id in object_ids:
            if obj_id not in self.objects:
                self.objects[str(obj_id)] = set()
            self.objects[str(obj_id)].add(frame_idx)

        self.annotated_frames.update({frame_idx: point_prompts})

    def task_consumer(self) -> None:
        while not self.stop_event.is_set():
            task = self.consume_requests()
            if task is None:
                time.sleep(0.2)
                continue

            try:
                self.status = enums.TaskStatus.BUSY
                if isinstance(task, schemas.SingleFramePointPromptInputCover):
                    if self.inference_run:
                        # todo: soft reset state
                        self.soft_reset_worker()
                    single_frame_response_cover = (
                        self._process_single_frame_point_prompt(task=task)
                    )
                    self.response_queue.put(single_frame_response_cover)
                    self.log.success(f"Processed {len(task.data)} annotations.")

                elif isinstance(task, schemas.RunInferenceInputCover):
                    if not self.objects:
                        self.log.error("No objects to run inference")
                        self.response_queue.put(
                            schemas.ErrorResponseCover(
                                message="No objects to run inference",
                                error={"message": "No objects to run inference"},
                            )
                        )
                        continue
                    else:
                        self._process_run_inference(task=task)
                        self.inference_run = True

                elif isinstance(task, schemas.RemoveObjectInputCover):
                    if self.inference_run:
                        self.soft_reset_worker()
                    self._process_remove_object(task=task)

                elif isinstance(task, schemas.ResetTaskInputCover):
                    self.log.warning("Reseting model")
                    self.model.reset_state()
                    self.objects.clear()
                    self.annotated_frames.clear()
                    self.status = enums.TaskStatus.READY

            except Exception as e:
                self.log.error(f"Error processing task: {e}")
                self.response_queue.put(
                    schemas.ErrorResponseCover(
                        message="Error processing task", error={"message": str(e)}
                    )
                )
            finally:
                self.status = enums.TaskStatus.READY

    def soft_reset_worker(self) -> None:
        """Soft resets worker. When user wants to add new object to the video after tracking completed,
        model_state should be reseted however this operation removes all objects from the video.

        With soft reset inference, all points re-added to model and user can continue to annotate
        """
        self.status = enums.TaskStatus.BUSY

        # temp point prompts from history
        tasks = []
        for frame_idx, point_prompts in self.annotated_frames.items():
            tasks.append(
                (
                    frame_idx,
                    schemas.SingleFramePointPromptInputCover(
                        data=point_prompts,
                        meta={"returnType": "bbox", "returnObjectThumbnail": False},
                    ),
                )
            )
        self.model.reset_state()
        self.objects.clear()
        self.annotated_frames.clear()

        for task in tasks:
            single_frame_response_cover = self._process_single_frame_point_prompt(
                task=task[1],
                #frame_idx=task[0],
            )
        self.inference_run = False

    def _process_single_frame_point_prompt(
        self,
        task: schemas.SingleFramePointPromptInputCover,
        frame_idx: Optional[int] = None,
    ) -> schemas.SingleFrameResponseCover:
        point_objects: List[schemas.SingleFrameAnnotationObject] = task.data

        if not point_objects:
            assert (
                frame_idx is not None
            ), "Frame index is required when no point prompt passed"
            out_frame_idx = frame_idx
            out_object_ids = []
            # get empty mask [1, H, W]
            masks = np.zeros((1, self.video_h, self.video_w), dtype=np.int64)
            self.log.critical(f"No point prompt passed for frame {frame_idx}")
        else:
            out_frame_idx, out_object_ids, masks = self.process_annotation_object(
                point_objects, frame_idx=frame_idx
            )

        # store action
        self.update_storage(
            frame_idx=out_frame_idx,
            object_ids=out_object_ids,
            point_prompts=point_objects,
        )
        print(f"{self.objects=}")
        print(f"{self.annotated_frames=}")

        post_process_return_type = task.meta.get("returnType", "mask")
        self.log.debug(f"Post Processing Target: {post_process_return_type}")
        processed_output = self.post_process_segmentation(
            frame_idx=out_frame_idx,
            out_object_ids=out_object_ids,
            masks=masks,
            return_type=post_process_return_type,
            task=task,
        )

        single_frame_response_cover = schemas.SingleFrameResponseCover(
            msg_type=post_process_return_type, data=processed_output
        )

        is_thumbnail_required = task.meta.get("returnObjectThumbnail", False)
        if is_thumbnail_required:
            
            thumbnails: Dict[str, str] = dict()
            for obj_id, mask in zip(out_object_ids, masks):
                try:
                    thumbnail = self.get_thumbnail_from_mask(
                        original_image=self.get_original_image(frame_idx=out_frame_idx),
                        mask=mask,
                        scale=0.5,
                        return_type="base64",
                    )
                    if isinstance(thumbnail, str):
                        thumbnails[str(obj_id)] = thumbnail
                except:
                    self.log.error(f"Error getting thumbnail for object: {obj_id}")
                    thumbnails[str(obj_id)] = self.get_fallback_thumbnail()
                # print(f"{obj_id=}, {thumbnail=}")
            single_frame_response_cover.meta["objectThumbnails"] = thumbnails
        return single_frame_response_cover

    def _process_run_inference(self, task: schemas.RunInferenceInputCover) -> None:
        self.status = enums.TaskStatus.IN_PROGRESS
        self.annotator.status = enums.AnnotationStatusEnum.IN_PROGRESS

        post_process_return_type = task.meta.get("returnType", "mask")
        self.log.warning(f"Starting video inference with {post_process_return_type=}")
        c = 0
        for out_frame_idx, out_obj_ids, masks in self.model.run_inference():
            processed_output = self.post_process_segmentation(
                frame_idx=out_frame_idx,
                out_object_ids=out_obj_ids,
                masks=masks,
                return_type=post_process_return_type,
                task=task,
            )
            # remember: now return single frame response on video processing -> can be changed
            self.response_queue.put(
                schemas.SingleFrameResponseCover(
                    msg_type=post_process_return_type, data=processed_output
                )
            )

            # export annotation to redis
            is_cached = self.annotator(
                segmentation_masks=masks,
                object_ids=out_obj_ids,
                color_mapping=self._get_id_color_mapping(task),
                frame_idx=out_frame_idx,
            )
            if is_cached:
                self.log.success(f"Exported annotation for frame {out_frame_idx}")
            else:
                self.log.error(f"Error exporting annotation for frame {out_frame_idx}")

        self.annotator.status = enums.AnnotationStatusEnum.READY
        self.status = enums.TaskStatus.READY
        self.log.success(f"Processed video inference")

    def _process_remove_object(self, task: schemas.RemoveObjectInputCover) -> None:
        self.status = enums.TaskStatus.BUSY
        object_ids_to_remove = task.data
        # check all objects exists
        if not all(obj_id in self.objects.keys() for obj_id in object_ids_to_remove):
            self.log.error(f"Invalid object ids: {object_ids_to_remove}")
            self.response_queue.put(
                schemas.ErrorResponseCover(
                    message="Invalid object ids to remove. Some objects do not exist",
                    error={"object_ids": object_ids_to_remove},
                )
            )
            return

        empty_frames = set()
        # remove objects
        for obj_id in object_ids_to_remove:
            for (
                frame_idx,
                point_prompts,
            ) in self.annotated_frames.items():  # int, List[AnnotationObject]
                for child in point_prompts:
                    if child.id == obj_id:
                        point_prompts.remove(child)
                        self.model.remove_object(object_id=obj_id)
                        break
            self.objects.pop(obj_id)

        # run inference for all remaining objects
        recursive_tasks: List[Tuple[int, schemas.SingleFramePointPromptInputCover]] = []
        for frame_idx, point_prompts in self.annotated_frames.items():
            recursive_tasks.append(
                (
                    frame_idx,
                    schemas.SingleFramePointPromptInputCover(
                        data=point_prompts,
                        meta=task.meta,
                    ),
                )
            )
        # check all annotated frames and remove empty frames
        for frame_idx, point_prompts in self.annotated_frames.items():
            if not point_prompts:
                empty_frames.add(frame_idx)
        for frame_idx in empty_frames:
            del self.annotated_frames[frame_idx]
        print(f"{self.objects=}")
        print(f"{self.annotated_frames=}")
        for rec_task in recursive_tasks:
            single_frame_response_cover = self._process_single_frame_point_prompt(
                task=rec_task[1],
                frame_idx=rec_task[0],
            )
            self.response_queue.put(single_frame_response_cover)

            # convert masks into images and encode (base64)
            # print(f"{out_object_ids=}, {masks=}")
            self.log.success(f"Processed {len(task.data)} annotations.")
        self.status = enums.TaskStatus.READY

    def post_process_segmentation(
        self,
        frame_idx: int,
        out_object_ids: List[Union[int, str]],
        masks: np.ndarray,
        return_type: Literal["polygon", "mask", "frame"] = "mask",
        task: Optional[schemas.ResponseCover] = None,
    ):
        if isinstance(task, schemas.ResponseCover):
            color_mapping = self._get_id_color_mapping(task)
        else:
            color_mapping = dict()
        if return_type == "polygon":
            return self._post_process_polygon(
                frame_idx=frame_idx,
                out_object_ids=out_object_ids,
                masks=masks,
                color_mapping=color_mapping,
                task=task,  # type: ignore
            )
        elif return_type == "mask":
            return self._post_process_segmentation_masks(
                frame_idx=frame_idx, out_object_ids=out_object_ids, masks=masks
            )
        elif return_type == "frame":
            return self._post_process_segmentation_frame(
                frame_idx=frame_idx,
                out_object_ids=out_object_ids,
                masks=masks,
                color_mapping=color_mapping,
                task=task,  # type: ignore
            )
        elif return_type == "bbox":
            return self._post_process_bbox(
                frame_idx=frame_idx,
                out_object_ids=out_object_ids,
                masks=masks,
                color_mapping=color_mapping,
                task=task,
            )

    def _post_process_segmentation_frame(
        self,
        frame_idx: int,
        out_object_ids: List[Union[int, str]],
        masks: np.ndarray,
        color_mapping: Dict[str, str],
        task: schemas.SingleFramePointPromptInputCover,
    ) -> Optional[schemas.FrameCover]:
        """Visualize segmentation masks on the frame

        Args:
            frame_idx (int): _description_
            out_object_ids (List[Union[int, str]]): _description_
            masks (np.ndarray): _description_
            task (Optional[schemas.SingleFramePointPromptInputCover]): _description_

        Returns:
            schemas.FrameCover: _description_
        """
        """
        - original frame required
        """
        if self.config is not None:
            original_frame = self.get_original_image(frame_idx=frame_idx)
            # original_frame = cv.cvtColor(original_frame, cv.COLOR_BGR2RGB)

            obj_id_mask_mapping: Dict[str, np.ndarray] = {
                str(obj_id): mask for obj_id, mask in zip(out_object_ids, masks)
            }

            visu = draw_masks_on_image(
                original_frame, masks=obj_id_mask_mapping, color=color_mapping
            )

            scale = task.meta.get("scale")
            if scale and isinstance(scale, (int, float)) and (0 < scale < 1):
                visu = cv.resize(visu, (0, 0), fx=float(scale), fy=float(scale))

            return schemas.FrameCover(
                frame_number=frame_idx,
                image_base64=image_to_base64(visu, encode=True),
                objects=[
                    schemas.FrameObject(
                        id=str(obj_id), objectColor=color_mapping[str(obj_id)]
                    )
                    for obj_id in out_object_ids
                ],
            )

    def _post_process_bbox(
        self,
        frame_idx: int,
        out_object_ids: List[Union[str, int]],
        masks: np.ndarray,
        color_mapping: Dict[str, str],
        task: Optional[schemas.ResponseCover],
    ) -> Optional[schemas.BboxCover]:
        """Returns BboxCover object via extracting bbox information from segmentation masks

        Args:
            frame_idx (int): corresponding frame index
            out_object_ids (List[Union[str, int]]): unique object ids
            masks (np.ndarray): segmentation masks
            color_mapping (Dict[str, str]): hex color mapping of object ids
            task (schemas.ResponseCover): _description_

        Returns:
            Optional[schemas.BboxCover]: BboxCover computed from masks
        """
        bboxes = mask_to_xyxy(masks, normlized=True)
        bbox_objects: List[schemas.BboxObject] = list()
        for obj_ids, bbox in zip(out_object_ids, bboxes):
            # print(f"{obj_ids=}, {bbox=}")
            bbox_objects.append(
                schemas.BboxObject(
                    id=obj_ids,
                    objecColor=color_mapping.get(str(obj_ids), "#FFFFFF"),
                    xmin=bbox[0],
                    ymin=bbox[1],
                    xmax=bbox[2],
                    ymax=bbox[3],
                    normalized=True,
                )
            )
        return schemas.BboxCover(frame_number=frame_idx, bboxes=bbox_objects)

    def _post_process_polygon(
        self,
        frame_idx: int,
        out_object_ids: List[Union[int, str]],
        masks: np.ndarray,
        color_mapping: Dict[str, str],
        task: schemas.ResponseCover,
    ) -> Optional[schemas.PolygonCover]:
        polygon_objects: List[schemas.PolygonObject] = list()
        for obj_id, mask in zip(out_object_ids, masks):
            polygon = mask_to_polygons(mask, normalized=True)
            for poly in polygon:
                polygon_object = schemas.PolygonObject(
                    id=obj_id,
                    objectColor=color_mapping.get(str(obj_id), "#FFFFFF"),
                    coordinates=poly.tolist(),
                    normalized=True,
                )
                polygon_objects.append(polygon_object)
        return schemas.PolygonCover(frame_number=frame_idx, polygons=polygon_objects)

    def _post_process_segmentation_masks(
        self,
        frame_idx: int,
        out_object_ids: List[Union[int, str]],
        masks: np.ndarray,
    ) -> schemas.MaskCover:
        out_masks = []
        for object_id, mask in zip(out_object_ids, masks):
            # convert mask to image
            mask_image = self.model.mask_to_image(mask)
            # convert image to base64
            mask_base64 = image_to_base64(mask_image)
            # create mask object
            mask_obj = schemas.Mask(id=object_id, mask=mask_base64, mask_type="mask")
            # append to list
            out_masks.append(mask_obj)
        return schemas.MaskCover(frame_number=frame_idx, masks=out_masks)

    def process_annotation_object(
        self,
        point_objects: List[schemas.SingleFrameAnnotationObject],
        frame_idx: Optional[int] = None,
    ) -> Tuple[int, List[Union[int, str]], np.ndarray]:
        """Processes point prompt by running segment-anything model

        Args:
            point_objects (List[schemas.SingleFrameAnnotationObject]): Point Prompt annotations

        Returns:
            Tuple[int, List[Union[int, str]], np.ndarray]: frame index, predicted object ids, predicted segmentation masks
        """
        # group by object_id
        points: List[np.ndarray] = [
            anno.numpy().astype(np.float32) for anno in point_objects
        ]
        labels: List[np.ndarray] = [
            anno.labels().astype(np.int32) for anno in point_objects
        ]
        object_ids: List[str] = [anno.id for anno in point_objects]
        frame_idxs: List[int] = [anno.frame_number for anno in point_objects]
        # assert if multiple frame indexes are present
        if frame_idx is None:
            assert (
                len(set(frame_idxs)) == 1
            ), "All child objects should be on the same frame"
            frame_idx = frame_idxs[0]

        start = time.time()
        out_frame_idx, out_obj_ids, out_mask_logits = self.model.add_point_prompt(
            points=points,
            labels=labels,
            object_ids=object_ids,  # note: fix the str vs int configuration # type: ignore
            frame_idx=frame_idx,
        )
        end = time.time()
        self.log.debug(
            f"Processed {len(points)} annotations in {end-start:.2f} seconds"
        )
        # filter out non requested object-ids from the output -> returns from SAM2 #FIXME: ?
        print(f"{out_obj_ids=}")
        requested_object_ids = [obj.id for obj in point_objects]
        out_mask_logits = self.extract_target_ids(all_ids=out_obj_ids, target_ids=requested_object_ids, array=out_mask_logits)

        return out_frame_idx, requested_object_ids, out_mask_logits
    
    def extract_target_ids(self, all_ids, target_ids, array):
        """
        Extracts slices of a numpy array corresponding to target IDs.

        Parameters:
        all_ids (list): List of all available IDs.
        target_ids (list): List of IDs to extract.
        array (numpy.ndarray): Numpy array of shape (N, W, H).

        Returns:
        numpy.ndarray: Extracted array of shape (N_requested, W, H).
        """
        # Find the indices of target IDs in the list of all IDs
        target_indices = [all_ids.index(target_id) for target_id in target_ids]
        
        # Extract the corresponding slices from the array
        result_array = array[target_indices]
        
        return result_array

    def get_original_image(self, frame_idx: int) -> np.ndarray:
        if self.config is None:
            raise RuntimeError("Could not get worker configuration")
        original_frame_path = os.path.join(
            self.config.task.video.frames_path,
            f"{str(frame_idx+1).zfill(8)}.jpg",
        )
        original_frame = cv.imread(original_frame_path)
        return original_frame

    def get_thumbnail_from_mask(
        self,
        original_image: np.ndarray,
        mask: np.ndarray,
        scale: float = 1.0,
        return_type: Literal["array", "base64"] = "array",
    ) -> Union[np.ndarray, str]:
        """Crops segmentation mask from original image as a thumbnail image

        Args:
            mask (np.ndarray): segmentation mask of corresponding object
            scale (float, optional): scale factor for thumbnail image. Defaults to 1.

        Returns:
            np.ndarray: thumbnail image of segmentation mask
        """
        # compute bboxes from mask
        if mask.ndim == 2:
            # add channel dimension [H, W] -> [1, H, W]
            mask = np.expand_dims(mask, axis=0)
        elif mask.ndim == 3:
            # make sure N is 1
            if mask.shape[0] != 1:
                raise ValueError("Invalid mask shape -> {mask.shape}")
        else:
            raise ValueError(f"Invalid mask shape -> {mask.shape}")

        bboxes = mask_to_xyxy(mask, normlized=False)
        # crop image using bbox
        if bboxes.shape[0] != 1:
            raise ValueError(f"Invalid bbox shape -> {bboxes.shape}")
        bbox = bboxes[0]
        xmin, ymin, xmax, ymax = bbox
        # crop image
        thumbnail = original_image[int(ymin) : int(ymax), int(xmin) : int(xmax)]

        if scale:
            thumbnail = cv.resize(thumbnail, (0, 0), fx=scale, fy=scale)

        if return_type == "base64":
            thumbnail = image_to_base64(thumbnail, encode=True)
        elif return_type == "array":
            pass
        else:
            raise ValueError(f"Invalid return type -> {return_type}")

        return thumbnail
    
    def get_fallback_thumbnail(self) -> str:
        """Returns default thumbnail image as base64 encoded string

        Returns:
            str: base64 encoded string of default thumbnail image
        """
        # todo: manage default thumbnail from assets
        im = np.zeros((100, 100, 3), dtype=np.uint8)
        im.fill(255)
        # put unknown text
        cv.putText(im, "Unknown", (10, 50), cv.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)
        return image_to_base64(im, encode=True)
        

    @staticmethod
    def _get_id_color_mapping(task: schemas.ResponseCover) -> Dict[str, str]:
        """Creates a mapping of object_id to color

        Args:
            task (schemas.PointPromptInputCover): _description_

        Returns:
            Dict[str, str]: object_id -> color(hex)
        """
        return {obj.id: obj.objectColor for obj in task.data}

    @staticmethod
    def _get_object_id_label_mapping(
        task: schemas.ResponseCover,
    ) -> Dict[str, Optional[str]]:
        """Creates a mapping of object_id to label

        Args:
            task (schemas.PointPromptInputCover): _description_

        Returns:
            Dict[str, str]: object_id -> label
        """
        return {obj.id: obj.label for obj in task.data}


def main(log_level: str, uuid: str) -> None:
    rcli = RedisClient(config=settings)

    logger = CustomLogger(level=log_level).get_logger()
    try:
        worker = Worker(logger=logger, worker_uuid=uuid)
    except Exception as e:
        logger.error(f"Error starting worker: {e}")
        rcli.set(f"task:{uuid}:status", enums.TaskStatus.FAILED.value)

        return
    worker.start()
    try:
        # while True:
        #    time.sleep(1)
        atexit.register(worker.stop)
        print("req")
    except KeyboardInterrupt:
        worker.stop()
        logger.info("Worker stopped")
        return


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--uuid", type=str, required=True, help="UUID of the worker")
    args = parser.parse_args()

    main(log_level="TRACE", uuid=args.uuid)
